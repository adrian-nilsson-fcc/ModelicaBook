# Documentation about the build process

## Source Code

To ensure all submodules are loaded, be sure to run:

```sh
$ git submodule init
$ git submodule update
```

## Docker Images

### New Way

I'm now using devcontainers (in VS Code) and I'll be updating the Gitlab CI/CD
pipelines soon. The images I'm using are much newer and are created by the
OpenModelica team themselves (including ARM images!).

### Docker on Macs

I'm currently using [`colima`](https://github.com/abiosoft/colima/) to support
Docker devcontainers on Mac. I installed it with `homebrew install colima`.

To start, run `colima start`. After that, normal `docker` commands should work
and VS Code should be able to use those tools to spawn devcontainers.

I also needed to define `LC_ALL` as follows within Docker containers:

```
$ export LC_ALL=C
```

### Old Way

These steps are designed to be performed by the `mtiller/book-builder` image.
To run this on an M1 Mac, run:

```sh
$ docker run -it --platform=linux/amd64 -v `pwd`:/opt/MBE/ModelicaBook mtiller/book-builder
```

or

```sh
$ docker run -it --platform=linux/amd64 -v `pwd`:/opt/MBE/ModelicaBook mtiller/flat-book-builder
```

...if you get lots of warnings about long file names.

## Step 1: Build Simulation Specifications

_Dependencies_: `text/specs.py`, `text/spec-hash` and Python

_Image_: `mtiller/book-builder` or `python:2.7.12` + `pip install jinja2`

_Artifacts_: `text/results/Makefile`, `text/results/json/*.json`,
`text/results/*.mos` and `text/plots/*.py`

_Job_: `make specs`

In this step, we collect information about the different "cases" we need to
present in the book. The actual cases are outlined in `text/specs.py`. This is
a largely declarative listing of the use cases.

Execution of this script produces the following files:

- The `text/results/Makefile` which defines how to build all simulations and
  their associated results.
- A `json` encoded representation of each case in `text/results/json/<CaseId>-case.json`.
- A script to build and simulation each individual case in `text/results/<CaseId>.mos`.
- A Python script to generate the plots for each case in `text/plots/<CaseId>.py`.

**NB**: The hash of the `text/specs.py` file is stored in the file
`text/spec-hash` and is used in the Makefile to determine if this step can be
skipped because the generated files out be identical to a previous run.

## Step 2: Build Simulation Results

_Dependencies_: Artifacts from running `text/specs.py`, `text/result-hash` and **`omc`**

_Image_: `mtiller/book-builder` (works on M1 if you run over and over) or perhaps `openmodelica/openmodelica:v1.17.0-minimal` (but not on M1)

_Artifacts_: `text/results/{executables,*_info.json,*_init.xml/*_res.mat}`

_Job_: `make results`

This step uses the OpenModelica compiler to build the following files for each
case defined in step 1.

- An executable for each case in `text/results/<CaseId>`.
- An "info" file generated by OpenModelica about each case in `text/results/<CaseId>_info.json`
- An initialization file in `text/results/<CaseId>_init.xml`
- A simulation result in `text/results/<CaseId>_res.mat`

The executables and init files are stored in `exes.tar.gz` (which is also used
by the simulation server API).

**NB**: The hash of the `ModelicaByExample` directory combined with the hash of
the `text/specs.py` file are stored in the file `text/results-hash` and is used
in the `text/Makefile` to determine if this step can be skipped because the
generated files out be identical to a previous run.

## Step 3: Build JSON (used by site generator)

_Dependencies_: `text/results/*.mos` and `text/plots/*.py` (guess)

_Image_: `mtiller/book-builder` or `sphinxdoc/sphinx` + `pip install matplotlib`

_Artifacts_: `text/build/json`

_Job_: `make json` or just `sphinx-build -b json -d build/doctrees  -q source build/json`

This generats the JSON output for the book. This includes HTML embedded in the
JSON. These files are required for the next step which is to translate the JSON
data into the book site.

## Step 4: Generating Site

## Step 5: Generate PDFs

_Dependencies_: `text/results/*.mos` and `text/plots/*.py` (guess)

_Image_: `mtiller/book-builder` or `sphinxdoc/sphinx` + `pip install matplotlib`

_Artifacts_: `text/build/latex`

_Job_: `make latex` (?) or just `sphinx-build -b latex -d build/doctrees  -q source build/latex`

## Step 6: Generate eBooks

## Step 7: Generate HTML (deprecated, don't need this)

## Step 8: Deploying Site

I'm using `now` to do the site deployment. Much simpler than all that mucking
about with AWS S3, IAM, permissions, keys, _etc._

It can also be published as a simple Docker image. All that is required is to
generate the files from Next and then wrap them in an NGINX container.

## Step 9: Build and Deploy API

_Dependencies_: `text/results/exes.tar.gz`

_Image_: `node` and `docker`

_Artifacts_: Docker image

_Job_: (see `.gitlab-ci.yaml`)
